{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **A7: Training Distillation vs LoRA**\n",
    "In this assignment, we will explore the comparison between Odd Layer and Even Layer Student Training Models and LoRA (Low-Rank Adaptation) on a distillation task using BERT from Huggingface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load Libraries and define device**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datasets\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 1. Hate Speech/Toxic Comment Dataset**\n",
    "Find and load a dataset that includes toxic comments or hate speech. This dataset will be used for training and evaluating the models. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 31060\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 3883\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 3883\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset('christinacdl/hate_speech_2_classes')\n",
    "\n",
    "# Print the dataset dictionary\n",
    "print(dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dataset` `christinacdl/hate_speech_2_classes` contains `38,826 number` of samples with `31.1K train`, `3.88K validation` and `3.88K test`. This dataset has two features `text` and `label`. The label is defined as `1 for toxic or hate speech` and `0 for non-toxic or non-hate speech`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'non-toxic': 0, 'toxic': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import ClassLabel\n",
    "\n",
    "# Define label mapping\n",
    "label_feature = ClassLabel(names=[\"non-toxic\", \"toxic\"])  # With label 0 = non-toxic, and label 1 = toxic\n",
    "\n",
    "# Apply casting to each split\n",
    "dataset = DatasetDict({\n",
    "    \"train\": dataset[\"train\"].cast_column(\"label\", label_feature),\n",
    "    \"validation\": dataset[\"validation\"].cast_column(\"label\", label_feature),\n",
    "    \"test\": dataset[\"test\"].cast_column(\"label\", label_feature),\n",
    "})\n",
    "\n",
    "# Now retrieve label names correctly\n",
    "label_list = dataset[\"train\"].features[\"label\"].names\n",
    "label2id = {v: i for i, v in enumerate(label_list)}\n",
    "\n",
    "print(\"Label Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'non-toxic', 1: 'toxic'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {i: v for v, i in label2id.items()}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels in Train: 2\n",
      "Number of unique labels in Validation: 2\n",
      "Number of unique labels in Test: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# Get number of unique labels for train, validation, and test\n",
    "num_labels_train = dataset[\"train\"].features[\"label\"].num_classes\n",
    "num_labels_val = dataset[\"validation\"].features[\"label\"].num_classes\n",
    "num_labels_test = dataset[\"test\"].features[\"label\"].num_classes\n",
    "\n",
    "print(f\"Number of unique labels in Train: {num_labels_train}\")\n",
    "print(f\"Number of unique labels in Validation: {num_labels_val}\")\n",
    "print(f\"Number of unique labels in Test: {num_labels_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Teacher Model\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "teacher_id = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(teacher_id)\n",
    "\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    teacher_id, \n",
    "    num_labels = num_labels_train,\n",
    "    id2label = id2label,\n",
    "    label2id = label2id,\n",
    ")\n",
    "\n",
    "teacher_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'label']\n",
      "{'text': \"i can understand that and if it ' s someone i know i will debate with them but i am not willing to spend that much time trying to change the mind of someone i do not know i tryed that with people and gun control and it just get stupid because they will not try to understand\", 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"].column_names)  # To see the columns of the dataset\n",
    "print(dataset[\"train\"][0])  # To check the format of an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    texts = [str(text) for text in examples[\"text\"]]  # Ensure all inputs are strings\n",
    "    return tokenizer(texts, padding=False, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d6c80c33914018a46398f57b926ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"i can understand that and if it ' s someone i know i will debate with them but i am not willing to spend that much time trying to change the mind of someone i do not know i tryed that with people and gun control and it just get stupid because they will not try to understand\", 'label': 1, 'input_ids': [101, 1045, 2064, 3305, 2008, 1998, 2065, 2009, 1005, 1055, 2619, 1045, 2113, 1045, 2097, 5981, 2007, 2068, 2021, 1045, 2572, 2025, 5627, 2000, 5247, 2008, 2172, 2051, 2667, 2000, 2689, 1996, 2568, 1997, 2619, 1045, 2079, 2025, 2113, 1045, 3046, 2098, 2008, 2007, 2111, 1998, 3282, 2491, 1998, 2009, 2074, 2131, 5236, 2138, 2027, 2097, 2025, 3046, 2000, 3305, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Check an example\n",
    "print(tokenized_datasets[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 31060\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3883\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3883\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text']\n"
     ]
    }
   ],
   "source": [
    "columns = [\"text\"]\n",
    "column_dataset = [item for item in columns if item == \"text\"]\n",
    "\n",
    "print(column_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 31060\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3883\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3883\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove column : 'premise', 'hypothesis', 'idx'\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(column_dataset)\n",
    "#rename column : 'labels'\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 101, 1045, 2064, 3305, 2008, 1998, 2065, 2009, 1005, 1055, 2619, 1045,\n",
       "        2113, 1045, 2097, 5981, 2007, 2068, 2021, 1045, 2572, 2025, 5627, 2000,\n",
       "        5247, 2008, 2172, 2051, 2667, 2000, 2689, 1996, 2568, 1997, 2619, 1045,\n",
       "        2079, 2025, 2113, 1045, 3046, 2098, 2008, 2007, 2111, 1998, 3282, 2491,\n",
       "        1998, 2009, 2074, 2131, 5236, 2138, 2027, 2097, 2025, 3046, 2000, 3305,\n",
       "         102])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] i can understand that and if it ' s someone i know i will debate with them but i am not willing to spend that much time trying to change the mind of someone i do not know i tryed that with people and gun control and it just get stupid because they will not try to understand [SEP]\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_datasets['train'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=1150).select(range(31060))\n",
    "small_eval_dataset = tokenized_datasets[\"validation\"].shuffle(seed=1150).select(range(3883))\n",
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=1150).select(range(3883))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    small_train_dataset, shuffle=True, batch_size=32, collate_fn=data_collator)\n",
    "test_dataloader = DataLoader(\n",
    "    small_test_dataset, batch_size=32, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(\n",
    "    small_eval_dataset, batch_size=32, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32]), torch.Size([32, 115]), torch.Size([32, 115]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "    \n",
    "batch['labels'].shape, batch['input_ids'].shape, batch['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"non-toxic\",\n",
       "    \"1\": \"toxic\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"non-toxic\": 0,\n",
       "    \"toxic\": 1\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.47.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertConfig\n",
    "# Get teacher configuration as a dictionnary\n",
    "configuration = teacher_model.config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Half the number of hidden layer\n",
    "configuration['num_hidden_layers'] //= 2\n",
    "# Convert the dictionnary to the student configuration\n",
    "configuration = BertConfig.from_dict(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create uninitialized student model\n",
    "model = type(teacher_model)(configuration)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert.modeling_bert import BertEncoder, BertModel\n",
    "from torch.nn import Module\n",
    "\n",
    "def distill_bert_weights(\n",
    "    teacher : Module,\n",
    "    student : Module,\n",
    "    init_method : str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Recursively copies the weights of the (teacher) to the (student).\n",
    "    This function is meant to be first called on a BertFor... model, but is then called on every children of that model recursively.\n",
    "    The only part that's not fully copied is the encoder, of which only half is copied based on init_method.\n",
    "    \"\"\"\n",
    "    # If the part is an entire BERT model or a BERTFor..., unpack and iterate\n",
    "    if isinstance(teacher, BertModel) or type(teacher).__name__.startswith('BertFor'):\n",
    "        for teacher_part, student_part in zip(teacher.children(), student.children()):\n",
    "            distill_bert_weights(teacher_part, student_part, init_method)\n",
    "    \n",
    "    # Else if the part is an encoder, copy one out of every layer based on init_method\n",
    "    elif isinstance(teacher, BertEncoder):\n",
    "        teacher_encoding_layers = [layer for layer in next(teacher.children())]  # 12 layers\n",
    "        student_encoding_layers = [layer for layer in next(student.children())]  # 6 layers\n",
    "        \n",
    "        # Odd Layers\n",
    "        if init_method == 'Odd Layer':\n",
    "            for i in range(len(student_encoding_layers)):\n",
    "                student_encoding_layers[i].load_state_dict(teacher_encoding_layers[i*2+1].state_dict())  # Odd layers, index starts from 1\n",
    "\n",
    "        # Even Layers\n",
    "        elif init_method == 'Even Layer':\n",
    "            for i in range(len(student_encoding_layers)):\n",
    "                student_encoding_layers[i].load_state_dict(teacher_encoding_layers[i*2].state_dict())  # Even layers, index starts from 0\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"init_method is invalid. Select between 'Odd Layer' or 'Even Layer'\")\n",
    "\n",
    "    # Else the part is a head or something else, copy the state_dict\n",
    "    else:\n",
    "        student.load_state_dict(teacher.state_dict())\n",
    "\n",
    "    return model  # Returning 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = ['Odd Layer', 'Even Layer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher parameters: 109483778\n",
      "Student (Odd Layer) parameters: 66956546\n",
      "Student (Even Layer) parameters: 66956546\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Count teacher model parameters\n",
    "print('Teacher parameters:', count_parameters(teacher_model))\n",
    "\n",
    "# Distill to students using different initialization methods\n",
    "for model_type in model_types:\n",
    "    # Create a student model\n",
    "    student_model = type(teacher_model)(configuration)\n",
    "    \n",
    "    # Apply distillation with the selected method\n",
    "    distill_bert_weights(teacher=teacher_model, student=student_model, init_method=model_type)\n",
    "    \n",
    "    # Count and print student model parameters\n",
    "    print(f'Student ({model_type}) parameters:', count_parameters(student_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student (Odd Layer) has 61.16% of the teacher model's parameters.\n",
      "Student (Even Layer) has 61.16% of the teacher model's parameters.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of parameters in the student model compared to the teacher model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def calculate_percentage_of_parameters(student_model, teacher_model):\n",
    "    student_params = count_parameters(student_model)\n",
    "    teacher_params = count_parameters(teacher_model)\n",
    "    return (student_params / teacher_params) * 100\n",
    "\n",
    "# Count teacher model parameters once\n",
    "teacher_params = count_parameters(teacher_model)\n",
    "\n",
    "# Print the percentage for each student model after distillation\n",
    "for model_type in model_types:\n",
    "    student_model = type(teacher_model)(configuration)\n",
    "    distill_bert_weights(teacher=teacher_model, student=student_model, init_method=model_type)\n",
    "    \n",
    "    # Calculate and print the percentage of parameters in the student model compared to the teacher model\n",
    "    percentage = calculate_percentage_of_parameters(student_model, teacher_model)\n",
    "    print(f\"Student ({model_type}) has {percentage:.2f}% of the teacher model's parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillKL(nn.Module):\n",
    "    \"\"\"\n",
    "    Distilling the Knowledge in a Neural Network\n",
    "    Compute the knowledge-distillation (KD) loss given outputs, labels.\n",
    "    \"Hyperparameters\": temperature and alpha\n",
    "\n",
    "    NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher\n",
    "    and student expects the input tensor to be log probabilities! \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DistillKL, self).__init__()\n",
    "\n",
    "    def forward(self, output_student, output_teacher, temperature=1):\n",
    "        '''\n",
    "        Note: the output_student and output_teacher are logits \n",
    "        '''\n",
    "        T = temperature #.cuda()\n",
    "        \n",
    "        KD_loss = nn.KLDivLoss(reduction='batchmean')(\n",
    "            F.log_softmax(output_student/T, dim=-1),\n",
    "            F.softmax(output_teacher/T, dim=-1)\n",
    "        ) * T * T\n",
    "        \n",
    "        return KD_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_div = DistillKL()\n",
    "criterion_cos = nn.CosineEmbeddingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "lr = 5e-5\n",
    "\n",
    "#training hyperparameters\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = teacher_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", \n",
    "    optimizer=optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 2. Odd Layer vs Even Layer Training** \n",
    "Based on the case-studies/distilBERT.ipynb, modify as follows:\n",
    "1) Train the student model using the odd layers {1, 3, 5, 7, 9, 11}from the 12-layer teacher to the 6-layer student. (1 point)\n",
    "2) Train the student model using the even layers {2, 4, 6, 8, 10, 12}from the 12-layer teacher to the 6-layer student. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Odd Layer =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7e49a392be4dccbea6e33f682425ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch at 1: Train loss 0.2143:\n",
      "  - Loss_cls: 0.5518\n",
      "  - Loss_div: 0.0533\n",
      "  - Loss_cos: 0.0379\n",
      "Epoch at 1: Test loss 0.4885\n",
      "Epoch at 1: Test Acc 0.8210\n",
      "Epoch at 2: Train loss 0.1928:\n",
      "  - Loss_cls: 0.4582\n",
      "  - Loss_div: 0.0851\n",
      "  - Loss_cos: 0.0352\n",
      "Epoch at 2: Test loss 0.4736\n",
      "Epoch at 2: Test Acc 0.8416\n",
      "Epoch at 3: Train loss 0.1789:\n",
      "  - Loss_cls: 0.3948\n",
      "  - Loss_div: 0.1069\n",
      "  - Loss_cos: 0.0349\n",
      "Epoch at 3: Test loss 0.4594\n",
      "Epoch at 3: Test Acc 0.8429\n",
      "Avg Metric 0.8351789853206283\n",
      "\n",
      "===== Even Layer =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33572c15c6ea4e29a998685c9b21a541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch at 1: Train loss 0.2145:\n",
      "  - Loss_cls: 0.5490\n",
      "  - Loss_div: 0.0557\n",
      "  - Loss_cos: 0.0388\n",
      "Epoch at 1: Test loss 0.4864\n",
      "Epoch at 1: Test Acc 0.8257\n",
      "Epoch at 2: Train loss 0.1930:\n",
      "  - Loss_cls: 0.4560\n",
      "  - Loss_div: 0.0872\n",
      "  - Loss_cos: 0.0358\n",
      "Epoch at 2: Test loss 0.4683\n",
      "Epoch at 2: Test Acc 0.8378\n",
      "Epoch at 3: Train loss 0.1778:\n",
      "  - Loss_cls: 0.3881\n",
      "  - Loss_div: 0.1095\n",
      "  - Loss_cos: 0.0357\n",
      "Epoch at 3: Test loss 0.4567\n",
      "Epoch at 3: Test Acc 0.8416\n",
      "Avg Metric 0.8350072967636707\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "model_scores = {}\n",
    "\n",
    "for model_type in model_types:\n",
    "\n",
    "    model = type(teacher_model)(configuration)\n",
    "    model = distill_bert_weights(teacher=teacher_model, student=model, init_method=model_type)\n",
    "    model = model.to(device)\n",
    "\n",
    "    print(f\"\\n===== {model_type} =====\")\n",
    "\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "    eval_metrics = 0\n",
    "\n",
    "    #training hyperparameters\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "    lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", \n",
    "    optimizer=optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=num_training_steps\n",
    "    )\n",
    "\n",
    "    # Lists to store losses for each epoch\n",
    "    train_losses = []\n",
    "    train_losses_cls = []\n",
    "    train_losses_div = []\n",
    "    train_losses_cos = []\n",
    "    eval_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        teacher_model.eval()\n",
    "        train_loss = 0\n",
    "        train_loss_cls = 0\n",
    "        train_loss_div = 0\n",
    "        train_loss_cos = 0\n",
    "        \n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            # compute student output\n",
    "            outputs = model(**batch) \n",
    "            # compute teacher output\n",
    "            with torch.no_grad():\n",
    "                output_teacher = teacher_model(**batch)\n",
    "\n",
    "            # assert size\n",
    "            assert outputs.logits.size() == output_teacher.logits.size()\n",
    "            \n",
    "            # cls loss \n",
    "            loss_cls  = outputs.loss\n",
    "            train_loss_cls += loss_cls.item()\n",
    "            # distillation loss\n",
    "            loss_div = criterion_div(outputs.logits, output_teacher.logits)\n",
    "            train_loss_div += loss_div.item()\n",
    "            # cosine loss\n",
    "            loss_cos = criterion_cos(output_teacher.logits, outputs.logits, torch.ones(output_teacher.logits.size()[0]).to(device))\n",
    "            train_loss_cos += loss_cos.item()\n",
    "            \n",
    "            # Average the loss and return it\n",
    "            loss = (loss_cls + loss_div + loss_cos) / 3\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            # accelerator.backward(loss)\n",
    "            # Step with optimizer\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        train_losses.append(train_loss / len(train_dataloader))\n",
    "        train_losses_cls.append(train_loss_cls / len(train_dataloader))\n",
    "        train_losses_div.append(train_loss_div / len(train_dataloader))\n",
    "        train_losses_cos.append(train_loss_cos / len(train_dataloader))\n",
    "\n",
    "        print(f'Epoch at {epoch+1}: Train loss {train_loss/len(train_dataloader):.4f}:')\n",
    "        print(f'  - Loss_cls: {train_loss_cls/len(train_dataloader):.4f}')\n",
    "        print(f'  - Loss_div: {train_loss_div/len(train_dataloader):.4f}')\n",
    "        print(f'  - Loss_cos: {train_loss_cos/len(train_dataloader):.4f}')\n",
    "\n",
    "        model.eval()\n",
    "        eval_loss = 0\n",
    "        for batch in eval_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "                \n",
    "            loss_cls = outputs.loss\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "            eval_loss += loss_cls.item()\n",
    "            # predictions, references = accelerator.gather((predictions, batch[\"labels\"]))\n",
    "            metric.add_batch(\n",
    "                predictions=predictions, \n",
    "                references=batch[\"labels\"])\n",
    "            \n",
    "        eval_metric = metric.compute()\n",
    "        eval_metrics += eval_metric['accuracy'] \n",
    "        eval_losses.append(eval_loss / len(eval_dataloader))  # Save the evaluation loss for plotting\n",
    "        \n",
    "        print(f\"Epoch at {epoch+1}: Test loss {eval_loss / len(eval_dataloader):.4f}\")\n",
    "        print(f\"Epoch at {epoch+1}: Test Acc {eval_metric['accuracy']:.4f}\")\n",
    "        \n",
    "    print('Avg Metric', eval_metrics/num_epochs)\n",
    "\n",
    "    model_scores[model_type] = {score_name: globals()[score_name] for score_name in [\n",
    "        'train_losses', 'train_losses_cls', 'train_losses_div', 'train_losses_cos', 'eval_losses'\n",
    "    ]}\n",
    "\n",
    "    progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the number of models and epochs\n",
    "epochs_list = range(1, num_epochs + 1)\n",
    "\n",
    "# Set limit for y-axis of all subplots to max and min values of losses\n",
    "loss_types = ['train_losses', 'train_losses_cls', 'train_losses_div', 'train_losses_cos', 'eval_losses']\n",
    "\n",
    "# Create subplots (fig, axes) using subplots() for more control\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))  # Assuming a 2x2 grid for 4 models\n",
    "\n",
    "# Flatten axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot for each model\n",
    "for i, (model_name, scores) in enumerate(model_scores.items()):\n",
    "    # For each model, plot the losses\n",
    "    axes[i].plot(epochs_list, scores['train_losses'], label='Total Train Loss')\n",
    "    axes[i].plot(epochs_list, scores['train_losses_cls'], label='Train Loss_cls')\n",
    "    axes[i].plot(epochs_list, scores['train_losses_div'], label='Train Loss_div')\n",
    "    axes[i].plot(epochs_list, scores['train_losses_cos'], label='Train Loss_cos')\n",
    "    axes[i].plot(epochs_list, scores['eval_losses'], label='Validation Loss')\n",
    "\n",
    "    # Set the title and labels\n",
    "    axes[i].set_title(model_name)\n",
    "    axes[i].set_xlabel('Epochs')\n",
    "    axes[i].set_ylabel('Loss')\n",
    "\n",
    "    # Set limits for y-axis dynamically based on each model's losses\n",
    "    y_upper_lim = max([score for loss_type in loss_types for score in scores[loss_type]])\n",
    "    y_lower_lim = min([score for loss_type in loss_types for score in scores[loss_type]])\n",
    "    axes[i].set_ylim(y_lower_lim, y_upper_lim)\n",
    "\n",
    "    # Add legend\n",
    "    axes[i].legend(loc='upper right')\n",
    "\n",
    "# Adjust layout\n",
    "fig.suptitle('Training and Validation Losses', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust for the main title space\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odd Layer Model Predictions:\n",
      "Text: I love you, Prediction: Non-Toxic\n",
      "Text: I hate you, Prediction: Toxic\n",
      "\n",
      "Even Layer Model Predictions:\n",
      "Text: I love you, Prediction: Non-Toxic\n",
      "Text: I hate you, Prediction: Toxic\n"
     ]
    }
   ],
   "source": [
    "# The text to classify\n",
    "texts = ['I love you', 'I hate you']\n",
    "\n",
    "# Tokenizing the texts\n",
    "inputs = tokenizer(texts, padding=False, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Function to perform inference with both models\n",
    "def predict_with_model(model, inputs):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions = logits.argmax(dim=-1)  # Get the predicted class\n",
    "    return predictions\n",
    "\n",
    "# Load your trained models (Odd Layer and Even Layer)\n",
    "odd_layer_model = type(teacher_model)(configuration)  # Ensure correct configuration\n",
    "odd_layer_model = distill_bert_weights(teacher=teacher_model, student=odd_layer_model, init_method='Odd Layer')\n",
    "odd_layer_model = odd_layer_model.to(device)\n",
    "\n",
    "even_layer_model = type(teacher_model)(configuration)  # Ensure correct configuration\n",
    "even_layer_model = distill_bert_weights(teacher=teacher_model, student=even_layer_model, init_method='Even Layer')\n",
    "even_layer_model = even_layer_model.to(device)\n",
    "\n",
    "# Predict toxicity for both models\n",
    "odd_layer_predictions = predict_with_model(odd_layer_model, inputs)\n",
    "even_layer_predictions = predict_with_model(even_layer_model, inputs)\n",
    "\n",
    "# Print results\n",
    "print(\"Odd Layer Model Predictions:\")\n",
    "for text, pred in zip(texts, odd_layer_predictions):\n",
    "    print(f\"Text: {text}, Prediction: {'Toxic' if pred.item() == 1 else 'Non-Toxic'}\")\n",
    "\n",
    "print(\"\\nEven Layer Model Predictions:\")\n",
    "for text, pred in zip(texts, even_layer_predictions):\n",
    "    print(f\"Text: {text}, Prediction: {'Toxic' if pred.item() == 1 else 'Non-Toxic'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4339914ebdeb45cc86714ab106b11726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch at 1: Train loss 0.4334:\n",
      "Epoch at 1: Test Acc 0.8280\n",
      "Epoch at 2: Train loss 0.2975:\n",
      "Epoch at 2: Test Acc 0.8331\n",
      "Epoch at 3: Train loss 0.1910:\n",
      "Epoch at 3: Test Acc 0.8411\n",
      "Avg Metric 0.8340630097004036\n"
     ]
    }
   ],
   "source": [
    "#Teacher model\n",
    "\n",
    "lr = 5e-5\n",
    "\n",
    "#training hyperparameters\n",
    "optimizer = optim.Adam(params=teacher_model.parameters(), lr=lr)\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "eval_metrics = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    teacher_model.train()\n",
    "    train_loss = 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        output_teacher = teacher_model(**batch)\n",
    "        # cls loss \n",
    "        loss = output_teacher.loss\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        # accelerator.backward(loss)\n",
    "        # Step with optimizer\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    print(f'Epoch at {epoch+1}: Train loss {train_loss/len(train_dataloader):.4f}:')\n",
    "    \n",
    "    teacher_model.eval()\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = teacher_model(**batch)\n",
    "    \n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        # predictions, references = accelerator.gather((predictions, batch[\"labels\"]))\n",
    "        metric.add_batch(\n",
    "            predictions=predictions, \n",
    "            references=batch[\"labels\"])\n",
    "        \n",
    "    eval_metric = metric.compute()\n",
    "    eval_metrics += eval_metric['accuracy'] \n",
    "    print(f\"Epoch at {epoch+1}: Test Acc {eval_metric['accuracy']:.4f}\")\n",
    "    \n",
    "print('Avg Metric', eval_metrics/num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully:\n",
      " - ./app/models/student_odd_layer_model\n",
      " - ./app/models/student_even_layer_model\n"
     ]
    }
   ],
   "source": [
    "# Define paths for saving\n",
    "odd_layer_model_path = \"./app/models/student_odd_layer_model\"\n",
    "even_layer_model_path = \"./app/models/student_even_layer_model\"\n",
    "\n",
    "# Save the models\n",
    "torch.save(odd_layer_model.state_dict(), odd_layer_model_path)\n",
    "torch.save(even_layer_model.state_dict(), even_layer_model_path)\n",
    "\n",
    "print(f\"Models saved successfully:\\n - {odd_layer_model_path}\\n - {even_layer_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 3. LoRA (Low-Rank Adaptation)**\n",
    "Implement LoRA to train the 12-layer student model. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 443,906 || all params: 109,927,684 || trainable%: 0.4038\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoModelForCausalLM\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "student_model = teacher_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS, \n",
    "    inference_mode=False, \n",
    "    r=8, \n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"query\", \"key\", \"value\"]\n",
    ")\n",
    "\n",
    "model_lora = get_peft_model(student_model, peft_config)\n",
    "model_lora.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from sklearn.metrics import accuracy_score\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)  # Convert logits to class predictions\n",
    "    accuracy = accuracy_score(labels, predictions)  # Compute accuracy\n",
    "    return {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PyEnv/lib/python3.9/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/f9/s34gjkt15353mj0f6b0668qh0000gn/T/ipykernel_89361/994673780.py:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac850aaabdcf417d8227804ea7e417ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3882 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4412, 'grad_norm': 9.27596378326416, 'learning_rate': 0.0004356002060793405, 'epoch': 0.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74581b44545547cb80b9ae1531ebcdac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7281646728515625, 'eval_accuracy': 0.8480556270924543, 'eval_runtime': 55.9505, 'eval_samples_per_second': 69.401, 'eval_steps_per_second': 34.709, 'epoch': 0.26}\n",
      "{'loss': 0.4217, 'grad_norm': 1.2456872463226318, 'learning_rate': 0.0003712004121586811, 'epoch': 0.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46678da2213346c9b1b58b5509029a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8204718828201294, 'eval_accuracy': 0.8501158897759464, 'eval_runtime': 63.9152, 'eval_samples_per_second': 60.752, 'eval_steps_per_second': 30.384, 'epoch': 0.52}\n",
      "{'loss': 0.4436, 'grad_norm': 18.52884292602539, 'learning_rate': 0.0003068006182380216, 'epoch': 0.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cedc1c4e4354198b97551060fc10b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7780385613441467, 'eval_accuracy': 0.8511460211176926, 'eval_runtime': 59.2007, 'eval_samples_per_second': 65.59, 'eval_steps_per_second': 32.804, 'epoch': 0.77}\n",
      "{'loss': 0.4322, 'grad_norm': 1.7750816345214844, 'learning_rate': 0.00024240082431736218, 'epoch': 1.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb5c01344f242b68cb9e614b54743e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8143168091773987, 'eval_accuracy': 0.844965233067216, 'eval_runtime': 47.5832, 'eval_samples_per_second': 81.604, 'eval_steps_per_second': 40.813, 'epoch': 1.03}\n",
      "{'loss': 0.305, 'grad_norm': 4.664235591888428, 'learning_rate': 0.00017800103039670274, 'epoch': 1.29}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c9134090c640c9807835644dd0eb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8618097305297852, 'eval_accuracy': 0.851403553953129, 'eval_runtime': 44.2536, 'eval_samples_per_second': 87.744, 'eval_steps_per_second': 43.883, 'epoch': 1.29}\n",
      "{'loss': 0.3241, 'grad_norm': 27.797239303588867, 'learning_rate': 0.00011360123647604328, 'epoch': 1.55}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167942bf3fed416082eeaed024f476bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.816728413105011, 'eval_accuracy': 0.8485706927633273, 'eval_runtime': 52.7744, 'eval_samples_per_second': 73.577, 'eval_steps_per_second': 36.798, 'epoch': 1.55}\n",
      "{'loss': 0.2926, 'grad_norm': 12.938920021057129, 'learning_rate': 4.9201442555383824e-05, 'epoch': 1.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17af6eb976f41fba033be5b5b7b8832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9655352234840393, 'eval_accuracy': 0.8529487509657482, 'eval_runtime': 47.6816, 'eval_samples_per_second': 81.436, 'eval_steps_per_second': 40.728, 'epoch': 1.8}\n",
      "{'train_runtime': 1475.0859, 'train_samples_per_second': 42.113, 'train_steps_per_second': 2.632, 'train_loss': 0.37588222686437406, 'epoch': 2.0}\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, default_data_collator\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./app/models/student-model-lora\",\n",
    "    learning_rate=5e-4,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    evaluation_strategy=\"steps\", \n",
    "    save_strategy=\"steps\",        \n",
    "    save_steps=500,               \n",
    "    eval_steps=500, \n",
    "    save_total_limit=2,  # Keeps only 2 latest checkpoints to save disk space\n",
    "    report_to=\"none\",  # Set to \"wandb\" or \"tensorboard\" if needed\n",
    "    push_to_hub=False,  # Set to True if pushing model to Hugging Face\n",
    "    bf16=True,\n",
    "    # fp16=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_lora,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()  # Make sure the model is trained\n",
    "\n",
    "# Save trained LoRA model properly\n",
    "trainer.save_model(\"./app/models/student-model-lora\")  \n",
    "model_lora.save_pretrained(\"./app/models/student-model-lora\")  \n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adapter_model.safetensors', 'checkpoint-3882', 'checkpoint-500', 'tokenizer_config.json', 'special_tokens_map.json', 'tokenizer.json', 'README.md', 'training_args.bin', 'adapter_config.json', 'vocab.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"./app/models/student-model-lora\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LoRA Model Predictions:\n",
      "Text: \"I love you\", Prediction: Non-Toxic\n",
      "Text: \"I hate you\", Prediction: Toxic\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "model_name = \"./app/models/student-model-lora\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load trained model with LoRA adapter\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "student_model_lora = PeftModel.from_pretrained(base_model, model_name)\n",
    "\n",
    "# Predict toxicity for both models\n",
    "student_model_lora_predictions = predict_with_model(student_model_lora, inputs)\n",
    "\n",
    "# Interpret results\n",
    "print(\"\\nLoRA Model Predictions:\")\n",
    "for text, pred in zip(texts, student_model_lora_predictions):\n",
    "    print(f'Text: \"{text}\", Prediction: {\"Toxic\" if pred.item() == 1 else \"Non-Toxic\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 4. Evaluation and Analysis**\n",
    "1) Evaluate the models on the test set, and analyze the performance of the models trained with Odd Layers, Even Layers, and LoRA. Discuss the differences in performance across the three methods.(0.5 point)\n",
    "    The difference in performance across the three methods are determined by comparing the results of the model performance.\n",
    "    - The models trained with Odd Layers may have lower performance than the models trained with Even Layers, especially for smaller datasets or less complex tasks.\n",
    "    - The models trained with LoRA may have higher performance than the models trained with Odd Layers, especially for smaller datasets or less complex tasks.\n",
    "    - The models trained with Odd Layers may require more computational resources, such as GPUs, to achieve good performance. This can be time-consuming and resource-intensive.\n",
    "    - The models trained with LoRA may require more compute resources, such as GPUs, to achieve good performance. This can be time-consuming and resource-intensive.\n",
    "\n",
    "2) Discuss the challenges encountered during the implementation, specifically comparing distillation fine-tuning models (Odd and Even Layer) with LoRA fine-tuning. Propose improvements or modifications to address the challenges. (0.5 point)\n",
    "\n",
    "    **Challenges encountered during the implementation:**\n",
    "    - Distillation fine-tuning models (Odd and Even Layers) often require a large amount of labeled data to achieve good performance. This can be time-consuming and resource-intensive.\n",
    "    - Training a model with LoRA requires a significant amount of compute resources, such as GPUs, to achieve good performance. This can be time-consuming and resource-intensive.\n",
    "    - Odd and Even Layers models require careful hyperparameter tuning to achieve good performance. These models can be sensitive to hyperparameter values, and finding the optimal hyperparameters can be challenging.\n",
    "    - The performance of Odd and Even Layers models may not be as good as LoRA models, especially for smaller datasets or less complex tasks.\n",
    "    - The performance of the models trained with LoRA may not be as good as the models trained with Odd and Even Layers, especially for smaller datasets or less complex tasks.\n",
    "  \n",
    "    **Improvements or modifications to address the challenges:**\n",
    "    - To address the challenge of training distillation fine-tuning models (Odd and Even Layers) with large labeled datasets, consider using transfer learning techniques, such as pre-training on a larger dataset and fine-tuning on a smaller dataset.\n",
    "    - To address the challenge of training a model with LoRA, consider using mixed-precision training techniques, such as mixed-precision training with NVIDIA Apex library, to accelerate the training process and reduce memory usage.\n",
    "    - To address the challenge of hyperparameter tuning for Odd and Even Layers models, consider using automated hyperparameter tuning techniques, such as Bayesian optimization or grid search.\n",
    "    - To address the challenge of achieving good performance for Odd and Even Layers models, consider using techniques like gradient checkpointing or layer pruning to reduce memory usage and improve training speed.\n",
    "    - To address the challenge of achieving good performance for the models trained with LoRA, consider using techniques like gradient checkpointing or layer pruning to reduce memory usage and improve training speed.\n",
    "    - To address the challenge of achieving good performance for both Odd and Even Layers models and the models trained with LoRA, consider using techniques like ensemble learning or model averaging to combine the predictions of multiple models.\n",
    "    \n",
    "    **Performance Analysis:**\n",
    "    | Model Type    | Training Loss | Test Set Performance |\n",
    "    | ------------- | ------------- |--------------------- |\n",
    "    | Odd Layer     | 0.1789        |  0.8351              |\n",
    "    | Even Layer    | 0.4567        |  0.8350              |\n",
    "    | LoRA          | 0.3758        |  0.8529              |\n",
    "\n",
    "    The performance of the models trained with Odd Layers and Even Layers is comparable, with the Even Layer model achieving slightly better performance. The models trained with LoRA achieve the best performance, with a test set performance of 0.8529. The improvements or modifications proposed to address the challenges can help improve the performance of the models, making them more suitable for real-world applications. The performance analysis provided in the table highlights the differences in performance across the three methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 5. Web Application**\n",
    "Develop a simple web application that classifies whether a given text input is toxic or hate speech. (1 point) The web application should:\n",
    "1) Include an input box where users can type in a text prompt.\n",
    "2) Based on the input, the model should classify and display whether the text is toxic or not. For example, if the input is ”I hate you”, the model might classify it as toxic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the web application, we can use a web framework like Flask. Here's a basic outline of the steps to follow:\n",
    "\n",
    "- Set up a Flask application.\n",
    "- Create a route for the web application, which will handle the input text and classify it using the trained models.\n",
    "- In the route handler, preprocess the input text using the same tokenizer as the models.\n",
    "- Use the trained models to predict the toxicity of the input text.\n",
    "- Display the web application\n",
    "- Use the trained models to display the web application.\n",
    "\n",
    "Please note that developing a full-fledged web application with user authentication, real-time predictions, and a user-friendly interface would require additional steps and infrastructure. For simplicity, I will provide a basic example of a Flask application that classifies toxicity using the trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
